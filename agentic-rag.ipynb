{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df76ed6",
   "metadata": {},
   "source": [
    "A basic system:\n",
    "\n",
    "User Query\n",
    "\n",
    "   â†“\n",
    "\n",
    "Decision (LLM)\n",
    "\n",
    "   â†“\n",
    "\n",
    "[Tool Call OR Direct Answer]\n",
    "\n",
    "   â†“\n",
    "   \n",
    "Final Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a29cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boring stuff\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "if not OPENROUTER_API_KEY:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY missing in environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e843aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 266.20it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: Why are embeddings useful?\n",
      "âš ï¸ OpenRouter failed, falling back to Mistral: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1770422400000'}, 'provider_name': None}}, 'user_id': 'user_33JOveQTDfa8tzJHX8UiRsza1LT'}\n",
      "Decision: retrieve\n",
      "Retrieved context: Embeddings capture semantic meaning of text.\n",
      "In RAG, documents are embedded into a vector space.\n",
      "âš ï¸ OpenRouter failed, falling back to Mistral: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1770422400000'}, 'provider_name': None}}, 'user_id': 'user_33JOveQTDfa8tzJHX8UiRsza1LT'}\n",
      "Embeddings capture semantic meaning of text, making it easier to compare and retrieve relevant information.\n",
      "\n",
      "QUESTION: What is RAG?\n",
      "âš ï¸ OpenRouter failed, falling back to Mistral: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1770422400000'}, 'provider_name': None}}, 'user_id': 'user_33JOveQTDfa8tzJHX8UiRsza1LT'}\n",
      "Decision: answer\n",
      "âš ï¸ OpenRouter failed, falling back to Mistral: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1770422400000'}, 'provider_name': None}}, 'user_id': 'user_33JOveQTDfa8tzJHX8UiRsza1LT'}\n",
      "**RAG** can refer to different things depending on the context. Here are the most common meanings:\n",
      "\n",
      "### 1. **Retrieval-Augmented Generation (RAG) in AI**\n",
      "   - A technique in **natural language processing (NLP)** and **machine learning** where a model retrieves relevant information from a knowledge base (like documents or databases) before generating a response.\n",
      "   - Used in **chatbots, search engines, and AI assistants** to improve accuracy by combining **retrieval-based** and **generative AI** approaches.\n",
      "   - Example: A chatbot uses RAG to fetch relevant documents before answering a user's question.\n",
      "\n",
      "### 2. **Red, Amber, Green (RAG) Status**\n",
      "   - A **project management** and **risk assessment** tool that uses color coding to indicate status:\n",
      "     - **Red** = Critical issue (urgent action needed)\n",
      "     - **Amber** = Warning (potential problem)\n",
      "     - **Green** = On track (no issues)\n",
      "   - Commonly used in **dashboards, reports, and risk matrices**.\n",
      "\n",
      "### 3. **Rag (Clothing or Fabric)**\n",
      "   - A piece of **old or torn cloth** used for cleaning, wiping, or as a rag doll.\n",
      "   - Example: \"He used a rag to clean the table.\"\n",
      "\n",
      "### 4. **RAG (Radio Amateur Group)**\n",
      "   - A term sometimes used in **amateur radio (ham radio)** communities.\n",
      "\n",
      "### 5. **RAG (Raising and Giving Society)**\n",
      "   - A student-led fundraising organization in the UK, often associated with universities.\n",
      "\n",
      "### Which one are you referring to?\n",
      "\n",
      "QUESTION: What clubs did Ronaldo play for?\n",
      "âš ï¸ OpenRouter failed, falling back to Mistral: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1770422400000'}, 'provider_name': None}}, 'user_id': 'user_33JOveQTDfa8tzJHX8UiRsza1LT'}\n",
      "Decision: retrieve\n",
      "Retrieved context: Ronaldo has played for Real Madrid, Manchester United, Juventus, Sporting Lisbon, Portugal and Al Nassr.\n",
      "FAISS is a library for efficient similarity search.\n",
      "âš ï¸ OpenRouter failed, falling back to Mistral: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '16', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1770394380000'}, 'provider_name': None}}, 'user_id': 'user_33JOveQTDfa8tzJHX8UiRsza1LT'}\n",
      "Ronaldo played for Sporting Lisbon, Manchester United, Real Madrid, Juventus, and Al Nassr.\n",
      "\n",
      "QUESTION: How do I bake a cake?\n",
      "âš ï¸ OpenRouter failed, falling back to Mistral: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '16', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1770394440000'}, 'provider_name': None}}, 'user_id': 'user_33JOveQTDfa8tzJHX8UiRsza1LT'}\n",
      "Decision: retrieve\n",
      "Retrieved context: Embeddings capture semantic meaning of text.\n",
      "FAISS is a library for efficient similarity search.\n",
      "âš ï¸ OpenRouter failed, falling back to Mistral: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '16', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1770394440000'}, 'provider_name': None}}, 'user_id': 'user_33JOveQTDfa8tzJHX8UiRsza1LT'}\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "from mistralai import Mistral\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Documents\n",
    "# ----------------------------\n",
    "\n",
    "documents = [\n",
    "    \"RAG stands for Retrieval-Augmented Generation.\",\n",
    "    \"In RAG, documents are embedded into a vector space.\",\n",
    "    \"FAISS is a library for efficient similarity search.\",\n",
    "    \"Large Language Models can hallucinate without grounding.\",\n",
    "    \"Embeddings capture semantic meaning of text.\",\n",
    "    \"Ronaldo has played for Real Madrid, Manchester United, Juventus, Sporting Lisbon, Portugal and Al Nassr.\"\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Chunking\n",
    "# ----------------------------\n",
    "\n",
    "def chunk(text, size=50):\n",
    "    words = text.split()\n",
    "    return [\" \".join(words[i:i+size]) for i in range(0, len(words), size)]\n",
    "\n",
    "chunks = []\n",
    "for d in documents:\n",
    "    chunks.extend(chunk(d))\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Embeddings\n",
    "# ----------------------------\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedder.encode(chunks).astype(\"float32\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. FAISS index\n",
    "# ----------------------------\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Retrieval tool\n",
    "# ----------------------------\n",
    "def retrieve(query, k=2):\n",
    "    q_emb = embedder.encode([query]).astype(\"float32\")\n",
    "    _, idx = index.search(q_emb, k)\n",
    "    return [chunks[i] for i in idx[0]]\n",
    "\n",
    "# ----------------------------\n",
    "# 6. LLM client \n",
    "# ----------------------------\n",
    "openrouter = OpenAI( #Primary \n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "mistral = Mistral( # secondary\n",
    "    api_key=os.getenv(\"MISTRAL_API_KEY\", \"\")\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Chat with fallback\n",
    "# ----------------------------\n",
    "\n",
    "def chat_with_fallback(messages, model_primary=\"stepfun/step-3.5-flash:free\"):\n",
    "    try:\n",
    "        # PRIMARY: OpenRouter\n",
    "        response = openrouter.chat.completions.create(\n",
    "            model=model_primary,\n",
    "            messages=messages,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ OpenRouter failed, falling back to Mistral:\", e)\n",
    "\n",
    "        # Optional small delay so you don't immediately re-hit limits\n",
    "        time.sleep(1 + random.random())\n",
    "\n",
    "        # FALLBACK: Mistral\n",
    "        res = mistral.chat.complete(\n",
    "            model=\"mistral-small-latest\",\n",
    "            messages=messages,\n",
    "            stream=False,\n",
    "        )\n",
    "        return res.choices[0].message.content\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 8. Decision (biased toward retrieval for learning)\n",
    "# ----------------------------\n",
    "\n",
    "def decide_action(query):\n",
    "    prompt = f\"\"\"\n",
    "You are a routing agent.\n",
    "\n",
    "Your job is to decide the action.\n",
    "\n",
    "Valid actions:\n",
    "- retrieve\n",
    "- answer\n",
    "\n",
    "Respond with ONLY ONE WORD.\n",
    "No explanations.\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "    raw = chat_with_fallback([\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]).lower().strip()\n",
    "\n",
    "    # HARD PARSING\n",
    "    if \"retrieve\" in raw:\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        return \"answer\"\n",
    "\n",
    "\n",
    "# ---------------------------- \n",
    "# 9. Answer step\n",
    "# ----------------------------\n",
    "def answer(query, context=None):\n",
    "    if context:\n",
    "        prompt = f\"\"\"\n",
    "Answer using ONLY the context below. Answer in less than 50 words.\n",
    "If the answer is not present, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "    else:\n",
    "        prompt = query\n",
    "\n",
    "    return chat_with_fallback([\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "# ----------------------------\n",
    "# 10. Agent loop\n",
    "# ----------------------------\n",
    "\n",
    "def agent(query):\n",
    "    decision = decide_action(query)\n",
    "    print(\"Decision:\", decision)\n",
    "\n",
    "    if decision == \"retrieve\":\n",
    "        context_chunks = retrieve(query)\n",
    "        context = \"\\n\".join(context_chunks)\n",
    "        print(\"Retrieved context:\", context)\n",
    "    else:\n",
    "        context = None\n",
    "\n",
    "    return answer(query, context)\n",
    "\n",
    "# ----------------------------\n",
    "# 11. Test\n",
    "# ----------------------------\n",
    "tests = [\n",
    "    \"Why are embeddings useful?\",\n",
    "    \"What is RAG?\",\n",
    "    \"What clubs did Ronaldo play for?\",\n",
    "    \"How do I bake a cake?\"\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    print(\"\\nQUESTION:\", t)\n",
    "    print(agent(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a81ff0",
   "metadata": {},
   "source": [
    "Now we used LLM to make the decision. But this is wasteful, too much time and $. So we move to a score based system\n",
    "\n",
    "User Query\n",
    "\n",
    "   â†“\n",
    "\n",
    "Vector similarity search\n",
    "\n",
    "   â†“\n",
    "\n",
    "If score > threshold â†’ RAG\n",
    "\n",
    "Else â†’ direct answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ee54d",
   "metadata": {},
   "source": [
    "If best_distance < THRESHOLD â†’ retrieve\n",
    "Else â†’ answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58c24cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is RAG?\n",
      "{'text': 'RAG stands for Retrieval-Augmented Generation.', 'distance': 0.45085984468460083}\n",
      "{'text': 'In RAG, documents are embedded into a vector space.', 'distance': 0.8678790926933289}\n",
      "\n",
      "Query: What clubs did Ronaldo play for?\n",
      "{'text': 'Ronaldo has played for Real Madrid, Manchester United, Juventus, Sporting Lisbon, Portugal and Al Nassr.', 'distance': 0.503292977809906}\n",
      "{'text': 'FAISS is a library for efficient similarity search.', 'distance': 1.8585604429244995}\n",
      "\n",
      "Query: How do I bake a cake?\n",
      "{'text': 'Embeddings capture semantic meaning of text.', 'distance': 1.9504539966583252}\n",
      "{'text': 'FAISS is a library for efficient similarity search.', 'distance': 1.9705548286437988}\n"
     ]
    }
   ],
   "source": [
    "#retrieval modified\n",
    "\n",
    "def retrieve_with_scores(query, k=2):\n",
    "    q_emb = embedder.encode([query]).astype(\"float32\")\n",
    "    distances, indices = index.search(q_emb, k)\n",
    "\n",
    "    results = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        results.append({\n",
    "            \"text\": chunks[idx],\n",
    "            \"distance\": float(dist)\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# distances\n",
    "\n",
    "queries = [\n",
    "    \"What is RAG?\",\n",
    "    \"What clubs did Ronaldo play for?\",\n",
    "    \"How do I bake a cake?\",\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(\"\\nQuery:\", q)\n",
    "    for r in retrieve_with_scores(q):\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87caf12",
   "metadata": {},
   "source": [
    "Lower distances = better results\n",
    "\n",
    "Lower = Retrieve, higher = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4ee4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a threshold\n",
    "THRESHOLD = 1.2\n",
    "\n",
    "# cheaper decision maker \n",
    "\n",
    "def should_retrieve(query, threshold=1.2):\n",
    "    results = retrieve_with_scores(query, k=1)\n",
    "    best_distance = results[0][\"distance\"]\n",
    "\n",
    "    print(\"Best distance:\", best_distance)\n",
    "\n",
    "    return best_distance < threshold\n",
    "\n",
    "\n",
    "# updated Agent loop\n",
    "\n",
    "def agent(query):\n",
    "    if should_retrieve(query):\n",
    "        results = retrieve_with_scores(query)\n",
    "        context = \"\\n\".join(r[\"text\"] for r in results)\n",
    "        print(\"Decision: retrieve\")\n",
    "        print(\"Context:\", context)\n",
    "        return answer(query, context)\n",
    "    else:\n",
    "        print(\"Decision: answer\")\n",
    "        return answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3340fc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: Why are embeddings useful?\n",
      "Best distance: 0.9399771690368652\n",
      "Decision: retrieve\n",
      "Context: Embeddings capture semantic meaning of text.\n",
      "In RAG, documents are embedded into a vector space.\n",
      "Embeddings capture semantic meaning of text, allowing documents to be represented in a vector space for retrieval.\n",
      "\n",
      "QUESTION: What is RAG?\n",
      "Best distance: 0.45085984468460083\n",
      "Decision: retrieve\n",
      "Context: RAG stands for Retrieval-Augmented Generation.\n",
      "In RAG, documents are embedded into a vector space.\n",
      "RAG stands for Retrievalâ€‘Augmented Generation, a technique where documents are embedded into a vector space to enable retrievalâ€‘augmented generation.\n",
      "\n",
      "QUESTION: What clubs did Ronaldo play for?\n",
      "Best distance: 0.503292977809906\n",
      "Decision: retrieve\n",
      "Context: Ronaldo has played for Real Madrid, Manchester United, Juventus, Sporting Lisbon, Portugal and Al Nassr.\n",
      "FAISS is a library for efficient similarity search.\n",
      "\n",
      "Ronaldo played for Realâ€¯Madrid, Manchesterâ€¯United, Juventus, Sportingâ€¯Lisbon, Portugal, and Alâ€¯Nassr.\n",
      "\n",
      "QUESTION: How do I bake a cake?\n",
      "Best distance: 1.9504539966583252\n",
      "Decision: answer\n",
      "Sure! Below is a straightforward, classic vanillaâ€‘cake recipe that works well for beginners and can be adapted to suit a variety of tastes and occasions. Feel free to customize the flavorings, frosting, or addâ€‘ins to make it your own.\n",
      "\n",
      "---\n",
      "\n",
      "## ðŸ“‹ What Youâ€™ll Need\n",
      "\n",
      "### Ingredients (makes one 9â€‘inch round cake or a 9Ã—13â€‘inch sheet cake)\n",
      "| Ingredient | Amount |\n",
      "|------------|--------|\n",
      "| Unsalted butter (roomâ€‘temperature) | 1 cup (226â€¯g) |\n",
      "| Granulated sugar | 1â€¯Â½â€¯cups (300â€¯g) |\n",
      "| Large eggs (roomâ€‘temperature) | 3 |\n",
      "| Pure vanilla extract | 2â€¯tsp |\n",
      "| Allâ€‘purpose flour | 2â€¯Â½â€¯cups (315â€¯g) |\n",
      "| Baking powder | 1â€¯Â½â€¯tsp |\n",
      "| Salt | Â½â€¯tsp |\n",
      "| Milk (whole or 2â€¯% works best) | 1â€¯cup (240â€¯ml) |\n",
      "| Optional flavor boosters: | |\n",
      "| â€¢ Â½â€¯tsp almond extract | for a nutty twist |\n",
      "| â€¢ 1â€¯cup chocolate chips, dried fruit, or nuts | for mixâ€‘ins |\n",
      "| â€¢ Zest of 1 lemon or orange | for citrus notes |\n",
      "\n",
      "### Tools\n",
      "- Two 9â€‘inch round cake pans (or one 9Ã—13â€‘inch pan) â€“ greased and lightly floured or lined with parchment.\n",
      "- Electric mixer (hand or stand) or a sturdy whisk.\n",
      "- Mixing bowls.\n",
      "- Sifter or fine mesh strainer (for flour & baking powder).\n",
      "- Rubber spatula.\n",
      "- Wire cooling rack.\n",
      "- Oven (preheated).\n",
      "\n",
      "---\n",
      "\n",
      "## ðŸ¥£ Stepâ€‘byâ€‘Step Instructions\n",
      "\n",
      "### 1. Preheat & Prep\n",
      "1. **Preheat** your oven to **350â€¯Â°F (177â€¯Â°C)**.  \n",
      "2. **Grease** the cake pans with butter or nonâ€‘stick spray, then dust lightly with flour or line the bottoms with parchment circles for easy release.\n",
      "\n",
      "### 2. Cream the Butter & Sugar\n",
      "1. In a large bowl, **beat the softened butter** on medium speed until smooth.  \n",
      "2. Add the **granulated sugar** and continue beating **3â€“5 minutes** until the mixture is **pale, fluffy, and has a light creamy texture**. This incorporates air, giving the cake a tender crumb.\n",
      "\n",
      "### 3. Add Eggs & Vanilla\n",
      "1. **Add the eggs one at a time**, beating well after each addition.  \n",
      "2. Stir in the **vanilla extract** (and any optional flavor extracts or zest).\n",
      "\n",
      "### 4. Combine Dry Ingredients\n",
      "1. **Sift** together the **flour, baking powder, and salt** into a separate bowl.  \n",
      "2. This prevents lumps and ensures even distribution of the leavening agent.\n",
      "\n",
      "### 5. Alternate Wet & Dry â€“ The â€œCreamingâ€ Method\n",
      "1. **Add â…“ of the dry mixture** to the butterâ€‘egg mixture. Mix on low speed until just combined.  \n",
      "2. **Pour in the milk**, mixing just until incorporated.  \n",
      "3. Add the **remaining dry ingredients** in the same way, mixing until the batter is smooth.  \n",
      "4. **Do NOT overâ€‘mix**; stop as soon as the flour is fully incorporated. Overâ€‘mixing can develop gluten and make the cake tough.\n",
      "\n",
      "### 6. Optional Addâ€‘Ins\n",
      "- If youâ€™re adding chocolate chips, nuts, or dried fruit, fold them in gently with a rubber spatula.\n",
      "\n",
      "### 7. Bake\n",
      "1. **Divide the batter** evenly between the prepared pans (or pour into a single pan).  \n",
      "2. **Smooth the tops** with the spatula.  \n",
      "3. **Bake** for **25â€“35 minutes** (round pans) or **30â€“40 minutes** (sheet pan), or until a **toothpick inserted into the center** comes out clean or with just a few moist crumbs.  \n",
      "4. **Rotate the pans** halfway through baking for even browning.\n",
      "\n",
      "### 8. Cool\n",
      "1. Allow the cakes to **cool in the pans** for **10 minutes**.  \n",
      "2. Run a thin knife around the edges, then **invert onto a wire rack** to cool completely (at least 30â€¯minutes).  \n",
      "   - Cool completely before frosting or cutting, otherwise the cake may crumble.\n",
      "\n",
      "### 9. Frost & Serve\n",
      "- **Basic Buttercream Frosting** (optional):  \n",
      "  - Beat Â½â€¯cup (115â€¯g) softened butter until creamy.  \n",
      "  - Add 2â€¯cups (250â€¯g) powdered sugar, 1â€¯tsp vanilla, and 2â€“3â€¯Tbsp milk; beat until light and fluffy.  \n",
      "  - Adjust thickness with more milk or sugar as needed.  \n",
      "- Spread frosting over the top and sides, or get creative with berries, sprinkles, or chocolate ganache.\n",
      "\n",
      "---\n",
      "\n",
      "## ðŸŽ‰ Tips & Variations\n",
      "\n",
      "| Goal | How to Adjust |\n",
      "|------|----------------|\n",
      "| **Moister cake** | Replace Â¼â€¯cup of milk with Â¼â€¯cup sour cream or yogurt. |\n",
      "| **Light & airy** | Separate the eggs: beat whites to stiff peaks, fold gently into batter at the end. |\n",
      "| **Chocolate cake** | Substitute Â½â€¯cup of the flour with Â½â€¯cup unsweetened cocoa powder and add Â½â€¯tsp instant coffee to intensify chocolate flavor. |\n",
      "| **Glutenâ€‘free** | Use a 1:1 glutenâ€‘free flour blend (make sure it contains xanthan gum). |\n",
      "| **Vegan** | Use plantâ€‘based butter/oil, replace eggs with Â¼â€¯cup unsweetened applesauce or a â€œflax eggâ€ (1â€¯Tbsp ground flax + 3â€¯Tbsp water, set 5â€¯min). |\n",
      "| **Flavor boost** | Add 1â€‘2â€¯tsp espresso powder for a subtle coffee note, or Â½â€¯tsp cinnamon for warmth. |\n",
      "\n",
      "---\n",
      "\n",
      "## ðŸ“š Quick Reference Cheat Sheet\n",
      "\n",
      "| Step | Time | Temperature |\n",
      "|------|------|--------------|\n",
      "| Preheat oven | â€“ | 350â€¯Â°F (177â€¯Â°C) |\n",
      "| Cream butter & sugar | 3â€“5 min | â€“ |\n",
      "| Add eggs & vanilla | 1â€“2 min | â€“ |\n",
      "| Mix dry ingredients | â€“ | â€“ |\n",
      "| Alternate wet/dry | 2â€“3 min | â€“ |\n",
      "| Bake | 25â€“40 min | 350â€¯Â°F (177â€¯Â°C) |\n",
      "| Cool in pan | 10 min | â€“ |\n",
      "| Cool on rack | 30+ min | â€“ |\n",
      "| Frost & serve | â€“ | â€“ |\n",
      "\n",
      "---\n",
      "\n",
      "### ðŸŽ‚ Final Thought\n",
      "The beauty of a basic cake is its versatility â€” once you master the foundation, you can experiment with flavors, textures, and decorations to suit any occasion. Happy baking! If you run into any specific questions (e.g., â€œWhy did my cake sink?â€ or â€œHow can I make a glutenâ€‘free version?â€), feel free to ask. ðŸ°\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "tests = [\n",
    "    \"Why are embeddings useful?\",\n",
    "    \"What is RAG?\",\n",
    "    \"What clubs did Ronaldo play for?\",\n",
    "    \"How do I bake a cake?\",\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    print(\"\\nQUESTION:\", t)\n",
    "    print(agent(t))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
